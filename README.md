The ultimate goal is to first learn bidirectional mappings between multimodal concepts and latent space to then perform next concept prediction. This sequence of latents is then used to condition a decoder to generate text (or images?). 
### Semantics:
Explores how one parses text and splits it into concepts for a model to then learn. 
### Ae-trainer: 
Trains auto-encoders by fine-tuning pretrained encoder and decoder models to create latent representations.
